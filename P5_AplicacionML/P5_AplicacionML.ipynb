{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5: Ejemplos de aplicación de algortimos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ingeniería Electrónica**\n",
    "\n",
    "**Inteligencia Artificial**\n",
    "\n",
    "**19/05/2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Árboles de decisión para diagnosticar cáncer de seno (mama) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de haber revisado los principios de Machine Learning, analizar un conjunto de datos real: el dataset de **_Breast Cancer Wisconsin_** (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)).\n",
    "\n",
    "Este conjunto de datos es un resultado de la investigación de imágenes médicas, y hoy se considera un ejemplo clásico. El conjunto de datos se creó a partir de imágenes digitalizadas de tejidos sanos (benignos) y cancerosos (malignos). Las imágenes se verían similares a la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplo_img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los investigadores realizaron la **extracción de características** en las imágenes. Pasaron por un total de 569 imágenes y extrajeron 30 características diferentes que describen las características de los núcleos celulares presentes en las imágenes, que incluyen:\n",
    "\n",
    "* textura del núcleo celular (representada por la desviación estándar de los valores de la escala de grises)\n",
    "* tamaño del núcleo celular (calculado como la media de las distancias desde el centro a los puntos en el perímetro)\n",
    "* suavidad del tejido (variación local en longitudes de radio)\n",
    "* compacidad tisular\n",
    "\n",
    "El **objetivo** de la investigación fue clasificar las muestras de tejido en benignas y malignas (una tarea de **clasificación binaria**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el conjunto de datos\n",
    "El conjunto de datos completo es parte de los conjuntos de datos de ejemplo de Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los datos están contenidos en una matriz de datos 2D `data.data`, donde las filas representan muestras de datos y las columnas son los valores de las características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los nombres de las características, reconocemos algunos de los que mencionamos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que esta es una tarea de clasificación binaria, esperamos encontrar exactamente dos nombres o categorías como objetivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo el árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X_train, y_train)\n",
    "dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no especificamos ningún parámetro previo, esperaríamos que este árbol de decisión crezca bastante y resulte en una puntuación perfecta en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error de prueba tampoco es malo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tree.dot\", 'w') as f:\n",
    "        f = tree.export_graphviz(dtc, out_file=f,\n",
    "                                 feature_names=data.feature_names,\n",
    "                                 class_names=data.target_names)\n",
    "!dot -Tpng tree.dot -o tree.png\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(\"tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "Declaramos la función `mostrar_resultados` que genere un reporte de los resultados del modelo incluyendo la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mostrar_resultados(y_test, pred_y):\n",
    "    conf_matrix = confusion_matrix(y_test, pred_y)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.heatmap(conf_matrix, xticklabels=data.target_names, yticklabels=data.target_names, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos a la función luego correr la predicción del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "mostrar_resultados(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntaje por defecto es la exactitud\n",
    "dtc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener el área bajo la curva ROC, la cual una metrica más conservadora. La curva ROC es un gráfico de la tasa positiva verdadera versus la tasa positiva falsa en varios umbrales de probabilidad que van de 0 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "prediction_prob = dtc.predict_proba(X_test)\n",
    "pos_prob = prediction_prob[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, pos_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifiquemos y exhibamos la curva ROC (bajo los umbrales de 0.0, 0.1, 0.2, ..., 1.0) de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos_prob = prediction_prob[:, 1]\n",
    "thresholds = np.arange(0.0, 1.2, 0.1)\n",
    "true_pos, false_pos = [0]*len(thresholds), [0]*len(thresholds)\n",
    "for pred, y in zip(pos_prob, y_test):\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if pred >= threshold:\n",
    "            # si real y predicion son 1\n",
    "            if y == 1:\n",
    "                true_pos[i] += 1\n",
    "                # si real es 0 mientras que la prediccion es 1\n",
    "            else:\n",
    "                false_pos[i] += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego calcular las tasas de verdadero y falso positivo para todas las configuraciones de umbral (recordar que hay 71 muestras benignas y 43 malignas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_rate = [tp / 71.0 for tp in true_pos]\n",
    "false_pos_rate = [fp / 43.0 for fp in false_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos trazar la curva ROC con matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(false_pos_rate, true_pos_rate, color='darkorange', lw=lw)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varios modelos\n",
    "Ahora queremos hacer una exploración de modelos. Por ejemplo, la profundidad de un árbol influye en su rendimiento. Si quisiéramos estudiar esta dependencia de manera más sistemática, podríamos repetir la construcción del árbol para diferentes valores de `max_depth`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_depths = np.array([1, 2, 3, 5, 7, 9, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada uno de estos valores, queremos ejecutar modelo completo de principio a fin. También queremos guardar los puntajes del entramiento y  de la prueba. Hacemos esto en un bucle for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "for d in max_depths:\n",
    "    dtc = tree.DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    train_score.append(dtc.score(X_train, y_train))\n",
    "    test_score.append(dtc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos trazar los puntajes en función de la profundidad del árbol usando Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_score, 'o-', linewidth=3, label='train')\n",
    "plt.plot(max_depths, test_score, 's-', linewidth=3, label='test')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace evidente cómo la profundidad del árbol influye en el rendimiento. Parece que cuanto más profundo es el árbol, mejor es el rendimiento en el conjunto de entrenamiento. \n",
    "Desafortunadamente, las cosas parecen un poco más confusas cuando se trata del rendimiento del conjunto de prueba. Aumentar la profundidad más allá del valor 3 no mejora aún más el puntaje de la prueba. ¿Quizás hay una configuración diferente de la que podríamos aprovechar que funcionaría mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa con el número mínimo de muestras requeridas para hacer de un nodo un nodo hoja?\n",
    "\n",
    "Repetimos el procedimiento de arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "min_samples = np.array([2, 4, 8, 16, 32])\n",
    "for s in min_samples:\n",
    "    dtc = tree.DecisionTreeClassifier(min_samples_leaf=s, random_state=42)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    train_score.append(dtc.score(X_train, y_train))\n",
    "    test_score.append(dtc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lleva a una gráfica diferente de la anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(min_samples, train_score, 'o-', linewidth=3, label='train')\n",
    "plt.plot(min_samples, test_score, 's-', linewidth=3,label='test')\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, aumentar `min_samples_leaf` no aparenta bien con el puntaje de entrenamiento. **Pero eso no es necesariamente algo malo**, porque sucede algo interesante en la curva azul: el puntaje de prueba pasa por un máximo para valores entre 4 y 8, lo que lleva a un mejor puntaje de prueba que hemos encontrado hasta ahora: mayor a 95%.\n",
    "Acabamos de aumentar nuestra puntuación inicial, simplemente ajustando los (hiper) parámetros del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio  \n",
    "\n",
    "Una gran cantidad de buenos resultados en Machine Learning en realidad provienen de largas horas de exploraciones de modelos mediante prueba y error. Antes de generar una nueva gráfica, piensen en: ¿Cómo se esperaría que se vea la gráfica? ¿Cómo debería cambiar el puntaje de entrenamiento al comenzar a restringir el número de nodos hoja (**max_leaf_nodes**)? ¿Qué pasa con **min_samples_split**? Además, ¿cómo cambian las cosas cuando se cambia del índice de **Gini** a  ganancia de información (**information gain**)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Árboles de decisión para regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos usar un árbol de decisión para que un modelo se **ajuste a una onda Seno**. también agregaremos algo de ruido a los puntos de datos usando el generador de números aleatorios de NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego creamos 100 valores x entre 0 y 5, y calculamos los valores seno correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.sort(5 * rng.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego agregamos ruido a cada punto de datos en y (usando `y[::2]`), escalado en 0.5 para que no introduzcamos demasiada variación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[::2] += 0.5 * (0.5 - rng.rand(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pequeña diferencia es que los criterios de división de Gini y la entropía no se aplican a las tareas de regresión. En cambio, scikit-learn proporciona dos criterios diferentes:\n",
    "\n",
    "* 'mse' (también conocido como reducción de varianza): este criterio calcula el error cuadrático medio (MSE) entre el valor real y la predicción, y divide el nodo que conduce al MSE más pequeño.\n",
    "\n",
    "* 'mae': este criterio calcula el error absoluto medio (MAE) entre el valor real y la predicción, y divide el nodo que conduce al MAE más pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el criterio 'mse', construiremos dos árboles, uno con una profundidad de 2 y otro con una profundidad de 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "regr1 = tree.DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "regr1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = tree.DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "regr2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces podemos usar el árbol de decisión como un regresor lineal. Para esto, creamos un conjunto de prueba con valores de x  muestreados en todo el rango de 0 a 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores `y_n` pronosticados se pueden obtener con el método `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = regr1.predict(X_test)\n",
    "y_2 = regr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si graficamos esto juntos, podemos ver cómo difieren los árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.scatter(X, y, c='k', s=50, label='data')\n",
    "plt.plot(X_test, y_1, label=\"max_depth=2\", linewidth=5)\n",
    "plt.plot(X_test, y_2, label=\"max_depth=5\", linewidth=3)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, la línea gruesa (en rojo) representa el árbol de regresión con profundidad 2. Se puede ver cómo el árbol intenta aproximar los datos utilizando estos pasos. La línea más delgada (en azul) pertenece al árbol de regresión con profundidad 5; La profundidad adicional ha permitido que el árbol tome decisiones mucho más finas. Por lo tanto, este árbol puede aproximar los datos aún mejor. Sin embargo, debido a esta potencia adicional, el árbol también es más susceptible a ajustar valores ruidosos, como se puede ver especialmente en el lado derecho de la gráfica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Detección de peatones con SVM y OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poco después de su introducción a principios de 1990, los SVM se hicieron rápidamente populares en la comunidad de ML, en gran parte debido a su éxito en la **clasificación temprana de dígitos escritos a mano**. Siguen siendo relevantes para este día, especialmente en aplicaciones como visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es aplicar SVM a un problema popular en visión por computador: la **detección de peatones**. A diferencia del **reconocimiento** (donde nombramos la categoría de un objeto), el objetivo de la detección es el decir si un objeto en particular (o en nuestro caso, un peatón) está presente en una imagen o no.\n",
    "\n",
    "En OpenCV es posible hacer esto en pocas líneas de código. Pero no aprenderemos nada si lo hacemos así. En cambio, construiremos todo el procesamiento desde cero. Obtendremos un conjunto de datos del mundo real, realizaremos la extracción de características utilizando el **histograma de gradientes orientados (HOG)** y le aplicaremos un SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea básica detrás de la mayoría de los algoritmos de detección es dividir una imagen en muchos parches pequeños y \n",
    "luego clasificar cada parche de imagen en si contiene un peatón o no.\n",
    "Para llegar a nuestro propio algoritmo de detección de peatones, debemos realizar los siguientes pasos:\n",
    "\n",
    "1. Construir una **base de datos de imágenes que contengan peatones**. Estas serán nuestras muestras de datos \"positivos\".\n",
    "2. Construir una **base de datos de imágenes que no contengan peatones**. Estas serán nuestras muestras de datos \"negativos\".\n",
    "3. Entrenar a un SVM en el conjunto de datos.\n",
    "4. Aplicar el SVM a cada parche de una imagen de prueba para determinar si la imagen contiene un peatón o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge opencv\n",
    "# pip install opencv-python\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo el conjunto de datos\n",
    "Trabajaremos con el conjunto de datos de peatones del MIT, que es libre de usar para fines no comerciales. \n",
    "\n",
    "El conjunto de datos se puede obtener de http://cbcl.mit.edu/software-datasets/PedestrianData.html. El botón de descarga nos lleva a un archivo llamado http://cbcl.mit.edu/projects/cbcl/software-datasets/pedestrians128x64.tar.gz.\n",
    "\n",
    "Sin embargo, dentro de la carptea pedestrians128x64 de esta práctica, se encuentran ya los archivos (.ppm) de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio de imágenes. Como se encuentra en el mismo directorio del jupyter notebook,\n",
    "# no es necesario especificar la ruta completa.\n",
    "imgdir = \"pedestrians128x64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos viene con un total de 924 imágenes en color de peatones, cada una escalada a 64 x 128 píxeles y alineada para que el cuerpo de la persona esté en el centro de la imagen. Escalar y alinear todas las muestras de datos es un paso importante del proceso.\n",
    "\n",
    "Estas imágenes fueron tomadas en Boston y Cambridge en una variedad de estaciones del año y bajo diferentes condiciones de iluminación. Podemos visualizar algunas imágenes de ejemplo leyendo la imagen con OpenCV y pasando una versión RGB de la imagen a Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(5):\n",
    "    filename = \"%s/per0010%d.ppm\" % (imgdir, i)\n",
    "    img = cv2.imread(filename)\n",
    "\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte del problema es encontrar una buena manera de representar estas imágenes. Debemos aplicar ingeniería de características (*feature engineering*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar el histograma de gradientes orientados (HOG)\n",
    "\n",
    "El HOG podría proporcionar la ayuda que estamos buscando para llevar a cabo esta tarea. HOG es un descriptor de características para imágenes. Se ha aplicado con éxito a diferentes tareas en visión por computador, y parece funcionar especialmente bien para clasificar a las personas.\n",
    "\n",
    "La idea esencial detrás de las características del HOG es que las formas locales y la apariencia de los objetos dentro de una imagen se pueden describir mediante la distribución de las direcciones de los bordes. La imagen se divide en pequeñas regiones conectadas, dentro de las cuales se compila un histograma de direcciones de gradiente (o **direcciones de borde**). Luego, el descriptor se ensambla concatenando los diferentes histogramas. Un ejemplo se muestra en la siguiente imagen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplo_hog.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen en el lado derecho muestra qué orientaciones de borde dominan en diferentes subregiones de la imagen. Se Puede ver por qué este descriptor sería particularmente adecuado para datos ricos en textura. Para mejorar el rendimiento, los histogramas locales también se pueden normalizar en contraste, lo que da como resultado una mejor invariancia a los cambios en la iluminación y el sombreado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El descriptor HOG es accesible en OpenCV mediante `cv2.HOGDescriptor`, que toma varios de argumentos de entrada, como el tamaño de la ventana de detección (tamaño mínimo del objeto a detectar, 48 x 96), el tamaño del bloque (qué tan grande cada bloque es, 16 x 16), el tamaño de la celda (8 x 8) y el paso de la celda (cuántos píxeles mover de una celda a la siguiente, 8 x 8). Para cada una de estas celdas, el descriptor HOG calcula un histograma de gradientes orientados utilizando nueve contenedores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = (48, 96)\n",
    "block_size = (16, 16)\n",
    "block_stride = (8, 8)\n",
    "cell_size = (8, 8)\n",
    "num_bins = 9\n",
    "hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, num_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque esta llamada a la función parece complicada, estos son en realidad los únicos valores para los que se implementa el descriptor HOG. El argumento que más importa es el tamaño de la ventana (`win_size`).\n",
    "\n",
    "Todo lo que queda por hacer es llamar a `hog.compute` en nuestras muestras de datos. Para esto, construimos un conjunto de datos de muestras positivas (`X_pos`) seleccionando aleatoriamente imágenes de peatones de nuestra carpeta. En la siguiente porción de código, seleccionamos al azar 400 imágenes de las más de 900 disponibles y les aplicamos el descriptor HOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "X_pos = []\n",
    "for i in random.sample(range(900), 400):\n",
    "    filename = \"%s/per%05d.ppm\" % (imgdir, i)\n",
    "    img = cv2.imread(filename)\n",
    "    if img is None:\n",
    "        print('No se pudo encontrar la imagen %s' % filename)\n",
    "        continue\n",
    "    X_pos.append(hog.compute(img, (64, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV requiere que la matriz de características contenga números de punto flotante de 32 bits y que las etiquetas de objetivo sean enteros de 32 bits. La conversión a matrices NumPy nos permitirá investigar fácilmente los tamaños de las matrices que creamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = np.array(X_pos, dtype=np.float32)\n",
    "y_pos = np.ones(X_pos.shape[0], dtype=np.int32)\n",
    "X_pos.shape, y_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que elegimos un total de 399 muestras de entrenamiento, cada una de las cuales tiene 1980 valores de características (que son los valores de características del HOG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando negativos\n",
    "\n",
    "Sin embargo, el verdadero desafío es encontrar el ejemplo perfecto de un \"no peatón\". Después de todo, es fácil pensar en imágenes de ejemplo de peatones. Pero, ¿qué es lo contrario de un peatón?\n",
    "\n",
    "Este es realmente un problema común cuando se intenta resolver nuevos problemas de ML. Tanto los laboratorios de investigación como las empresas dedican mucho tiempo a crear y anotar nuevos conjuntos de datos que se ajustan a su propósito específico.\n",
    "\n",
    "Una buena primera aproximación para encontrar lo opuesto a un peatón es reunir un conjunto de datos de imágenes que se parezcan a las imágenes de la clase positiva pero que no contengan peatones. Estas imágenes pueden contener cualquier cosa, como automóviles, bicicletas, calles, casas y tal vez incluso bosques, lagos o montañas.\n",
    "\n",
    "Un buen lugar para comenzar es el conjunto de datos de escenas urbanas y naturales del Laboratorio de Cognición Visual Computacional del MIT. El conjunto de datos completo se puede obtener de http://olivalab.mit.edu/datasets.html, pero ya se ha recopilado una buena cantidad de imágenes de categorías como campo abierto, ciudades, montañas y bosques. Se encuentran en la carpeta `pedestrians_neg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negdir = \"pedestrians_neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imágenes son en color, en formato `.jpeg` y tienen 256 x 256 píxeles. Sin embargo, para usarlos como muestras de una clase negativa que se combinan con nuestras imágenes de peatones anteriormente, debemos asegurarnos de que todas las imágenes tengan el mismo tamaño de píxel. Además, las cosas representadas en las imágenes deberían estar aproximadamente a la misma escala. Por lo tanto, queremos recorrer todas las imágenes en el directorio (a través de `os.listdir`) y recortar una región de interés (ROI) de 64 x 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hroi = 128\n",
    "wroi = 64\n",
    "X_neg = []\n",
    "for negfile in os.listdir(negdir):\n",
    "    filename = '%s/%s' % (negdir, negfile)\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    for j in range(5):\n",
    "        rand_y = random.randint(0, img.shape[0] - hroi)\n",
    "        rand_x = random.randint(0, img.shape[1] - wroi)\n",
    "        roi = img[rand_y:rand_y + hroi, rand_x:rand_x + wroi, :]\n",
    "        X_neg.append(hog.compute(roi, (64, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos de este procedimiento se muestran en la siguiente imagen:\n",
    "<img src=\"ejemplo_neg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olvidamos asegurarnos de que todos los valores de caracteristicas son números de punto flotante de 32 bits. Además, la etiqueta de objetivo de estas imágenes debe ser -1, correspondiente a la clase negativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neg = np.array(X_neg, dtype=np.float32)\n",
    "y_neg = -np.ones(X_neg.shape[0], dtype=np.int32)\n",
    "X_neg.shape, y_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos concatenar todas las muestras positivas (`X_pos`) y negativas (`X_neg`) en un único conjunto de datos `X`, que dividimos usando la función ya conocida `train_test_split` de scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_pos, X_neg))\n",
    "y = np.concatenate((y_pos, y_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de la máquina de vectores de soporte\n",
    "\n",
    "Envolvemos el procedimiento de entrenamiento en una función, para que sea más fácil repetir el procedimiento en el futuro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    svm = cv2.ml.SVM_create()\n",
    "    svm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo puede hacerse para la función de puntuación. Aquí pasamos una matriz de características X y un vector de etiquetas y, pero no especificamos si nos referimos al conjunto entrenamiento o al de prueba. De hecho, desde el punto de vista de la función, no importa a qué conjunto pertenezcan las muestras de datos, siempre que tengan el formato correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_svm(svm, X, y):\n",
    "    from sklearn import metrics\n",
    "    _, y_pred = svm.predict(X)\n",
    "    return metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos entrenar y calificar el SVM con dos llamadas cortas a funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = train_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_svm(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_svm(svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias al descriptor de funciones del HOG, no hay errores en el conjunto de entrenamiento. Sin embargo, nuestro rendimiento de generalización es abismal (64.6 por ciento), ya que es mucho menor que el rendimiento del entrenamiento (100 por ciento). **Esto es una indicación de que el modelo está sobreajustando los datos**. El hecho de que esté funcionando mucho mejor en el conjunto de entrenamiento que en el conjunto de prueba significa que el modelo ha recurrido a memorizar las muestras de entrenamiento, en lugar de tratar de abstraerlo en una regla de decisión significativa.\n",
    "\n",
    "¿Qué podemos hacer para mejorar el rendimiento del modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Bootstrapping al modelo\n",
    "\n",
    "Una forma interesante de mejorar el rendimiento de nuestro modelo es usar **bootstrapping**. Esta idea se aplicó en uno de los primeros papers sobre el uso de SVM en combinación con características HOG para la detección de peatones.\n",
    "\n",
    "Su idea era simple. Después de entrenar al SVM en el conjunto de entrenamiento, calificaron el modelo y descubrieron que el modelo producía algunos falsos positivos. Recordar que falso positivo significa que el modelo predijo un positivo (+) para una muestra que realmente era negativa (-). En nuestro contexto, esto significaría que el SVM creía falsamente que una imagen contenía un peatón. Si esto sucede para una imagen en particular en el conjunto de datos, este ejemplo es claramente problemático. Por lo tanto, debemos agregarlo al conjunto de entrenamiento y volver a entrenar el SVM con el que causa problema, para que el algoritmo pueda aprender a clasificarlo correctamente. Este procedimiento puede repetirse hasta que el SVM proporcione un rendimiento satisfactorio.\n",
    "\n",
    "Hagamos lo mismo. Repetiremos el procedimiento de entrenamiento un máximo de tres veces. Después de cada iteración, identificamos los falsos positivos en el conjunto de prueba y los agregamos al conjunto de entrenamiento para la siguiente iteración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = []\n",
    "score_test = []\n",
    "for j in range(3):\n",
    "    svm = train_svm(X_train, y_train)\n",
    "    score_train.append(score_svm(svm, X_train, y_train))\n",
    "    score_test.append(score_svm(svm, X_test, y_test))\n",
    "    \n",
    "    _, y_pred = svm.predict(X_test)\n",
    "    false_pos = np.logical_and((y_test.ravel() == -1), (y_pred.ravel() == 1))\n",
    "    if not np.any(false_pos):\n",
    "        print('hecho')\n",
    "        break\n",
    "    X_train = np.concatenate((X_train, X_test[false_pos, :]), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_test[false_pos]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos permite mejorar el modelo con el tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, logramos una precisión del 64.6 por ciento en la primera ronda, pero pudimos obtener hasta un perfecto 100 por ciento en la segunda ronda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de peatones en una imagen más grande\n",
    "\n",
    "Lo que queda por hacer es conectar el procedimiento de clasificación SVM con el proceso de detección. La forma de hacerlo es repetir nuestra clasificación para cada parche en la imagen. Dividimos la imagen en parches y clasificamos cada parche en que contiene un peatón o no.\n",
    "\n",
    "Por lo tanto, si queremos hacer esto, tenemos que recorrer todos los parches posibles en una imagen, cambiando cada vez nuestra región de interés por un pequeño número de píxeles de paso (`stride`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = cv2.imread('prueba_peaton.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 16\n",
    "found = []\n",
    "for ystart in np.arange(0, img_test.shape[0], stride):\n",
    "    for xstart in np.arange(0, img_test.shape[1], stride):\n",
    "        if ystart + hroi > img_test.shape[0]:\n",
    "            continue\n",
    "        if xstart + wroi > img_test.shape[1]:\n",
    "            continue\n",
    "        roi = img_test[ystart:ystart + hroi, xstart:xstart + wroi, :]\n",
    "        feat = np.array([hog.compute(roi, (64, 64))])\n",
    "        _, ypred = svm.predict(feat)\n",
    "        if np.allclose(ypred, 1):\n",
    "            found.append((ystart, xstart, hroi, wroi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los peatones podrían aparecer no solo en varios lugares sino también en varios tamaños, tendríamos que reescalar la imagen y repetir todo el proceso. Afortunadamente, OpenCV tiene una función conveniente para esta tarea de detección de múltiples escalas en forma de la función `detectMultiScale`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica, cuando se resuelve una tarea como la detección de peatones, a menudo se confía en clasificadores SVM preestablecidos que están integrados en OpenCV. Este es lo que se indicaba al inicio. Al cargar `cv2.HOGDescriptor_getDaimlerPeopleDetector()` o `cv2.HOGDescriptor_getDefaultPeopleDetector()`, podemos comenzar con solo unas pocas líneas de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogdef = cv2.HOGDescriptor()\n",
    "hogdef.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "found, _ = hogdef.detectMultiScale(img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos marcar a los peatones detectados en la imagen recorriendo los cuadros delimitadores en `found`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB))\n",
    "from matplotlib import patches\n",
    "for f in found:\n",
    "    ax.add_patch(patches.Rectangle((f[0], f[1]), f[2], f[3], color='y', linewidth=3, fill=False))\n",
    "plt.savefig('detectado.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
